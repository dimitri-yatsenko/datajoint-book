{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The `make` Method\n",
    "\n",
    "The `make()` method defines the computational logic for auto-populated tables (`dj.Imported` and `dj.Computed`).\n",
    "This chapter describes its anatomy, constraints, and the three-part pattern that enables long-running computations while preserving transactional integrity.\n",
    "\n",
    "## Input: The Key\n",
    "\n",
    "The `make()` method receives a single argument: the **key** dictionary.\n",
    "This key identifies which entity to compute—it contains the primary key attributes from the table's *key source*.\n",
    "\n",
    "The key source is automatically determined by DataJoint as the join of all parent tables referenced by foreign keys in the auto-populated table's primary key, minus entries that already exist:\n",
    "\n",
    "```python\n",
    "# For a table with dependencies -> Image and -> BlobParamSet,\n",
    "# the key source is effectively:\n",
    "Image.proj() * BlobParamSet.proj() - Detection\n",
    "```\n",
    "\n",
    "Each call to `make()` processes exactly one key from this source.\n",
    "\n",
    "## The Three Parts\n",
    "\n",
    "A well-structured `make()` method has three distinct parts:\n",
    "\n",
    "### 1. Fetch\n",
    "\n",
    "Retrieve the necessary data from **upstream tables** using the provided key:\n",
    "\n",
    "```python\n",
    "def make(self, key):\n",
    "    # 1. FETCH: Get data from upstream tables\n",
    "    image = (Image & key).fetch1(\"image_data\")\n",
    "    params = (BlobParamSet & key).fetch1()\n",
    "```\n",
    "\n",
    "The key restricts each upstream table to exactly the relevant row(s).\n",
    "Use `fetch1()` when expecting a single row, `fetch()` for multiple rows.\n",
    "\n",
    "**Upstream tables** are those reachable from the current table by following foreign key references upward through the dependency graph.\n",
    "The fetch step should only access:\n",
    "- Tables that are upstream dependencies (directly or transitively via foreign keys)\n",
    "- Part tables of those upstream tables\n",
    "\n",
    "This constraint ensures computational reproducibility—the computation depends only on data that logically precedes it in the pipeline.\n",
    "\n",
    "### 2. Compute\n",
    "\n",
    "Perform the actual computation or data transformation:\n",
    "\n",
    "```python\n",
    "    # 2. COMPUTE: Perform the transformation\n",
    "    blobs = detect_blobs(\n",
    "        image,\n",
    "        min_sigma=params[\"min_sigma\"],\n",
    "        max_sigma=params[\"max_sigma\"],\n",
    "        threshold=params[\"threshold\"],\n",
    "    )\n",
    "```\n",
    "\n",
    "This is the scientific or business logic—image processing, statistical analysis, simulation, or any transformation that produces derived data.\n",
    "The compute step should be a pure function of the fetched data.\n",
    "\n",
    "### 3. Insert\n",
    "\n",
    "Store the results in the table (and any part tables):\n",
    "\n",
    "```python\n",
    "    # 3. INSERT: Store results\n",
    "    self.insert1({**key, \"blob_count\": len(blobs)})\n",
    "    self.Blob.insert([{**key, \"blob_id\": i, **b} for i, b in enumerate(blobs)])\n",
    "```\n",
    "\n",
    "The key must be included in the inserted row to maintain referential integrity.\n",
    "For master-part structures, insert both the master row and all part rows within the same `make()` call.\n",
    "\n",
    "## Restrictions on Auto-Populated Tables\n",
    "\n",
    "Auto-populated tables (`dj.Imported` and `dj.Computed`) enforce important constraints:\n",
    "\n",
    "1. **No manual insertion**: Users cannot insert data into auto-populated tables outside of the `make()` method. All data must come through the `populate()` mechanism.\n",
    "\n",
    "2. **Upstream-only fetching**: The fetch step should only access tables that are *upstream* in the pipeline—reachable by following foreign key references from the current table toward its dependencies.\n",
    "\n",
    "3. **Complete key inclusion**: Inserted rows must include the full primary key (the input `key` plus any additional primary key attributes defined in the table).\n",
    "\n",
    "These constraints ensure:\n",
    "- **Reproducibility**: Results can be regenerated by re-running `populate()`\n",
    "- **Provenance**: Every row traces back to specific upstream data\n",
    "- **Consistency**: The dependency graph accurately reflects data flow\n",
    "\n",
    "## Complete Example\n",
    "\n",
    "```python\n",
    "@schema\n",
    "class Detection(dj.Computed):\n",
    "    definition = \"\"\"\n",
    "    -> Image\n",
    "    -> BlobParamSet\n",
    "    ---\n",
    "    blob_count : int\n",
    "    \"\"\"\n",
    "\n",
    "    class Blob(dj.Part):\n",
    "        definition = \"\"\"\n",
    "        -> master\n",
    "        blob_id : int\n",
    "        ---\n",
    "        x : float\n",
    "        y : float\n",
    "        sigma : float\n",
    "        \"\"\"\n",
    "\n",
    "    def make(self, key):\n",
    "        # 1. FETCH\n",
    "        image = (Image & key).fetch1(\"image_data\")\n",
    "        params = (BlobParamSet & key).fetch1()\n",
    "\n",
    "        # 2. COMPUTE\n",
    "        blobs = detect_blobs(\n",
    "            image,\n",
    "            min_sigma=params[\"min_sigma\"],\n",
    "            max_sigma=params[\"max_sigma\"],\n",
    "            threshold=params[\"threshold\"],\n",
    "        )\n",
    "\n",
    "        # 3. INSERT\n",
    "        self.insert1({**key, \"blob_count\": len(blobs)})\n",
    "        self.Blob.insert([{**key, \"blob_id\": i, **b} for i, b in enumerate(blobs)])\n",
    "```\n",
    "\n",
    "## Transactional Integrity\n",
    "\n",
    "By default, each `make()` call executes inside an **ACID transaction**:\n",
    "\n",
    "- **Atomicity** — The entire computation either commits or rolls back as a unit\n",
    "- **Isolation** — Partial results are never visible to other processes\n",
    "- **Consistency** — The database moves from one valid state to another\n",
    "\n",
    "The transaction wraps the entire `make()` execution, including all fetches and inserts.\n",
    "This guarantees that computed results are correctly associated with their specific inputs.\n",
    "\n",
    "## The Three-Part Pattern for Long Computations\n",
    "\n",
    "For long-running computations (hours or days), holding a database transaction open for the entire duration causes problems:\n",
    "- Database locks block other operations\n",
    "- Transaction timeouts may occur\n",
    "- Resources are held unnecessarily\n",
    "\n",
    "The **three-part `make` pattern** solves this by separating the computation from the transaction:\n",
    "\n",
    "```python\n",
    "@schema\n",
    "class SignalAverage(dj.Computed):\n",
    "    definition = \"\"\"\n",
    "    -> RawSignal\n",
    "    ---\n",
    "    avg_signal : float\n",
    "    \"\"\"\n",
    "\n",
    "    def make_fetch(self, key):\n",
    "        \"\"\"Step 1: Fetch input data (outside transaction)\"\"\"\n",
    "        raw_signal = (RawSignal & key).fetch1(\"signal\")\n",
    "        return (raw_signal,)\n",
    "\n",
    "    def make_compute(self, key, fetched):\n",
    "        \"\"\"Step 2: Perform computation (outside transaction)\"\"\"\n",
    "        (raw_signal,) = fetched\n",
    "        avg = raw_signal.mean()\n",
    "        return (avg,)\n",
    "\n",
    "    def make_insert(self, key, fetched, computed):\n",
    "        \"\"\"Step 3: Insert results (inside brief transaction)\"\"\"\n",
    "        (avg,) = computed\n",
    "        self.insert1({**key, \"avg_signal\": avg})\n",
    "```\n",
    "\n",
    "### How It Works\n",
    "\n",
    "DataJoint executes the three parts with verification:\n",
    "\n",
    "```\n",
    "fetched = make_fetch(key)           # Outside transaction\n",
    "computed = make_compute(key, fetched)  # Outside transaction\n",
    "\n",
    "<begin transaction>\n",
    "fetched_again = make_fetch(key)     # Re-fetch to verify\n",
    "if fetched != fetched_again:\n",
    "    <rollback>                       # Inputs changed—abort\n",
    "else:\n",
    "    make_insert(key, fetched, computed)\n",
    "    <commit>\n",
    "```\n",
    "\n",
    "The key insight: **the computation runs outside any transaction**, but referential integrity is preserved by re-fetching and verifying inputs before insertion.\n",
    "If upstream data changed during computation, the job is cancelled rather than inserting inconsistent results.\n",
    "\n",
    "### Benefits\n",
    "\n",
    "| Aspect | Standard `make()` | Three-Part Pattern |\n",
    "|--------|-------------------|--------------------|\n",
    "| Transaction duration | Entire computation | Only final insert |\n",
    "| Database locks | Held throughout | Minimal |\n",
    "| Suitable for | Short computations | Hours/days |\n",
    "| Integrity guarantee | Transaction | Re-fetch verification |\n",
    "\n",
    "### Generator Syntax Alternative\n",
    "\n",
    "The three-part pattern can also be expressed as a generator, which is more concise:\n",
    "\n",
    "```python\n",
    "def make(self, key):\n",
    "    # 1. FETCH\n",
    "    raw_signal = (RawSignal & key).fetch1(\"signal\")\n",
    "    computed = yield (raw_signal,)  # Yield fetched data\n",
    "\n",
    "    if computed is None:\n",
    "        # 2. COMPUTE\n",
    "        avg = raw_signal.mean()\n",
    "        computed = (avg,)\n",
    "        yield computed  # Yield computed results\n",
    "\n",
    "    # 3. INSERT\n",
    "    (avg,) = computed\n",
    "    self.insert1({**key, \"avg_signal\": avg})\n",
    "    yield  # Signal completion\n",
    "```\n",
    "\n",
    "DataJoint automatically detects the generator pattern and handles the three-part execution.\n",
    "\n",
    "## When to Use Each Pattern\n",
    "\n",
    "| Computation Time | Pattern | Rationale |\n",
    "|------------------|---------|----------|\n",
    "| Seconds to minutes | Standard `make()` | Simple, transaction overhead acceptable |\n",
    "| Minutes to hours | Three-part | Avoid long transactions |\n",
    "| Hours to days | Three-part | Essential for stability |\n",
    "\n",
    "The three-part pattern trades off fetching data twice for dramatically reduced transaction duration.\n",
    "Use it when computation time significantly exceeds fetch time.\n",
    "\n",
    ":::{seealso}\n",
    "- [Populate](050-populate.ipynb) — The `populate()` method that calls `make()`\n",
    "- [Transactions](040-transactions.ipynb) — ACID semantics in DataJoint\n",
    "- [Master-Part](../30-design/053-master-part.ipynb) — Inserting master and part rows together\n",
    ":::"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
