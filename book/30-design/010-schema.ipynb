{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\ntitle: Schemas\nauthors:\n  - name: Dimitri Yatsenko\n---\n\n# What is a schema?\n\nThe term schema has two related meanings in the context of databases:\n\n## 1. Schema as a Data Blueprint\nA **schema** is a formal specification of the structure of data and the rules governing its integrity.\nIt serves as a blueprint that defines how data is organized, stored, and accessed within a database.\nThis ensures that the database reflects the rules and requirements of the underlying business or research project it supports.\n\nIn structured data models, such as the relational model, a schema provides a robust framework for defining:\n* The structure of tables (relations) and their attributes (columns).\n* Rules and constraints that ensure data consistency, accuracy, and reliability.\n* Relationships between tables, such as primary keys (unique identifiers for records) and foreign keys (references to related records in other tables).\n\n### Aims of Good Schema Design\n* **Data Integrity**: Ensures consistency and prevents anomalies.\n* **Query Efficiency**: Facilitates fast and accurate data retrieval, supports complex queries, and optimizes database performance.\n* **Scalability**: Allows the database to grow and adapt as data volumes increase.\n\n### Key Elements of Schema Design\n* **Tables and Attributes**: Each table is defined with specific attributes (columns), each assigned a data type.\n* **Primary Keys**: Uniquely identify each record in a table.\n* **Foreign Keys**: Establish relationships between entities in tables.\n* **Indexes**: Support efficient queries.\n\nThrough careful schema design, database architects create systems that are both efficient and flexible, meeting the current and future needs of an organization. The schema acts as a living document that guides the structure, operations, and integrity of the database.\n\n## 2. Schema as a Database Module\n\nIn complex database designs, the term \"schema\" is also used to describe a distinct module of a larger database with its own namespace that groups related tables together. \nThis modular approach:\n* Separates tables into logical groups for better organization.\n* Avoids naming conflicts in large databases with multiple schemas."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Declaring a schema\n",
    "Before you can create tables, you must declare a schema to serve as a namespace for your tables.\n",
    "Each schema requires a unique name to distinguish it within the database.\n",
    "\n",
    "Here’s how to declare a schema in DataJoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-08-27 04:10:41,167][INFO]: Connecting root@localhost:3306\n",
      "[2024-08-27 04:10:41,184][INFO]: Connected root@localhost:3306\n"
     ]
    }
   ],
   "source": [
    "import datajoint as dj\n",
    "\n",
    "# Define the schema\n",
    "schema = dj.Schema('schema_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Using the `schema` Object\n\nThe schema object groups related tables together and helps prevent naming conflicts.\n\nBy convention, the object created by `dj.Schema` is named `schema`. Typically, only one schema object is used in any given Python namespace, usually at the level of a Python module.\n\nThe schema object serves multiple purposes:\n* **Creating Tables**: Used as a *class decorator* (`@schema`) to declare tables within the schema. \nFor details, see the next section, [Tables](015-table.ipynb)\n* **Visualizing the Schema**: Generates diagrams to illustrate relationships between tables.\n* **Exporting Data**: Facilitates exporting data for external use or backup.\n\nWith this foundation, you are ready to begin declaring tables and building your data pipeline."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Multi-Schema Pipelines\n\nAs pipelines grow, you will organize tables into multiple schemas. Each schema groups related tables together—for example, `subject`, `acquisition`, `processing`, and `analysis`.\n\n## Simple Scripts vs. Full Projects\n\nFor **learning, exploration, and simple pipelines**, you can define schemas directly in Python scripts or Jupyter notebooks, just like the examples throughout this book. This is the easiest way to get started:\n\n```python\n# Simple script: my_pipeline.py\nimport datajoint as dj\n\nschema = dj.Schema('my_experiment')\n\n@schema\nclass Subject(dj.Manual):\n    definition = \"\"\"\n    subject_id : int\n    ---\n    subject_name : varchar(100)\n    \"\"\"\n\n@schema  \nclass Session(dj.Manual):\n    definition = \"\"\"\n    -> Subject\n    session_date : date\n    ---\n    notes : varchar(500)\n    \"\"\"\n```\n\nFor **production deployment** with multiple collaborators, version control, and automated workers, you should organize the pipeline as a proper Python package. See [Pipeline Projects](090-pipeline-project.md) for the full project structure including:\n* Standard layout with `src/workflow/`\n* Configuration with `pyproject.toml`\n* Docker deployment\n\n## Convention: One Schema = One Module\n\nWhether using simple scripts or full projects, the fundamental convention is: **one database schema corresponds to one Python module** (or one script/notebook for simple cases).\n\nThis ensures:\n* Each module has exactly one `schema` object\n* Clear dependency management between schemas\n* No circular imports\n\n## Example Schema Module\n\nHere is a typical schema module defining the `subject` schema:"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;32mimport\u001b[0m \u001b[0mdatajoint\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdj\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;31m# Define the subject management schema\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0mschema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSchema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"subject_management\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;32mclass\u001b[0m \u001b[0mSubject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mManual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdefinition\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\"\u001b[0m\n",
      "\u001b[0;34m    subject_id : int\u001b[0m\n",
      "\u001b[0;34m    ---\u001b[0m\n",
      "\u001b[0;34m    subject_name : varchar(50)\u001b[0m\n",
      "\u001b[0;34m    species : varchar(50)\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%pycat code/subject.py"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "# Working with Existing Schemas\n\nThis section describes how to work with database schemas without access to the original code that generated the schema. These situations often arise when:\n- The database is created by another user who has not shared the generating code yet\n- The database schema is created from a programming language other than Python\n- You need to explore an existing database before writing new code\n\n## Listing Available Schemas\n\nYou can use the `dj.list_schemas` function to list the names of database schemas available to you:\n\n```python\nimport datajoint as dj\ndj.list_schemas()\n```\n\n## Connecting to an Existing Schema\n\nJust as with a new schema, you start by creating a `schema` object to connect to the chosen database schema:\n\n```python\nschema = dj.Schema('existing_schema_name')\n```\n\nIf the schema already exists, `dj.Schema` is initialized as usual and you may plot the schema diagram. But instead of seeing class names, you will see the raw table names as they appear in the database:\n\n```python\ndj.Diagram(schema)\n```\n\n## Spawning Missing Classes\n\nWhen you connect to an existing schema without the original Python code, you can view the diagram but cannot interact with the tables. A similar situation arises when another developer has added new tables to the schema but has not yet shared the updated module code with you.\n\nYou may use the `schema.spawn_missing_classes` method to *spawn* classes into the local namespace for any tables missing their classes:\n\n```python\nschema.spawn_missing_classes()\n```\n\nNow you may interact with these tables as if they were declared right here in your namespace.\n\n## Creating a Virtual Module\n\nThe `spawn_missing_classes` method creates new classes in the local namespace. However, it is often more convenient to import a schema with its Python module, equivalent to:\n```python\nimport university as uni\n```\n\nWe can mimic this import without having access to `university.py` using the `create_virtual_module` function:\n\n```python\nimport datajoint as dj\n\nuni = dj.create_virtual_module('university', 'existing_schema_name')\n```\n\nNow `uni` behaves as an imported module complete with the `schema` object and all the table classes. You can use it like any other module:\n\n```python\ndj.Diagram(uni)\nuni.Student - uni.StudentMajor\n```\n\n## Virtual Module Options\n\n`dj.create_virtual_module` takes optional arguments:\n\n### create_schema\nThe `create_schema=False` argument (default) assures that an error is raised when the schema does not already exist. Set it to `True` if you want to create an empty schema:\n\n```python\n# This will raise an error if 'nonexistent' schema doesn't exist\ndj.create_virtual_module('what', 'nonexistent')\n\n# This will create the schema if it doesn't exist\ndj.create_virtual_module('what', 'nonexistent', create_schema=True)\n```\n\n### create_tables\nThe `create_tables=False` argument is passed to the schema object. It prevents the use of the schema object of the virtual module for creating new tables in the existing schema. This is a precautionary measure since virtual modules are often used for completed schemas.\n\nYou may set this argument to `True` if you wish to add new tables to the existing schema:\n\n```python\nuni = dj.create_virtual_module('university', 'existing_schema_name', create_tables=True)\n\n@uni.schema\nclass NewTable(dj.Manual):\n    definition = \"\"\"\n    -> uni.Student \n    ---\n    example : varchar(255)\n    \"\"\"\n```\n\nA more common approach when you need to add tables is to create a new `schema` object and use the `spawn_missing_classes` function to make the existing classes available.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropping a Schema\n",
    "\n",
    "Dropping a schema in DataJoint involves permanently deleting all the tables within that schema and the schema itself from the database. This is a significant action because it removes not only the tables but also all the data stored within those tables. To drop a schema, you typically use the `schema.drop()` method, where schema is the schema object you defined earlier in your code. \n",
    "\n",
    "When you execute this command, DataJoint will prompt you to confirm the action, as it is irreversible and will result in the loss of all data associated with the schema. This operation is especially powerful because it cascades through all tables within the schema, removing each one. \n",
    "\n",
    "It's crucial to ensure that any data within the schema is either no longer needed or has been adequately backed up before dropping the schema, as this action will permanently remove all traces of the data and the schema’s structure from the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping a schema\n",
    "schema.drop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}