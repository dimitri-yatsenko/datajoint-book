{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Normalization\n",
        "\n",
        "Normalization is a collection of design principles in relational databases that ensure data integrity and maintainability and makes databases more amenable to analysis and inference. \n",
        "\n",
        "Several approaches to normalization have been proposed, differing in their conceptual foundations and how they guide the design process.\n",
        "\n",
        "This chapter explores three distinct approaches to normalization:\n",
        "\n",
        "1. **Mathematical Normalization**: Based on Codd's normal forms, rooted in predicate calculus and functional dependencies\n",
        "2. **Entity Normalization**: Based on Chen's Entity-Relationship Model, focused on identifying well-defined entity types\n",
        "3. **Workflow Normalization**: Based on Entity-Workflow Model, emphasizing steps in workflow execution.\n",
        "\n",
        "Each approach provides a different lens for understanding what makes a schema well-designed, yet all converge on the same practical principles.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Approach 1: Mathematical Normalization\n",
        "\n",
        "Edgar F. Codd developed formal normalization theory in the early 1970s, rooted in the mathematical foundations of the relational model [@10.1145/358024.358054].\n",
        "This approach is deeply tied to **predicate calculus** and the original conceptualization of relations.\n",
        "\n",
        "### The Predicate Calculus Foundation\n",
        "The intellectual foundation of the relational model lies in predicate calculus, a branch of mathematical logic.\n",
        "\n",
        "1. **Predicates and Relations**: A **predicate** is a function or statement about one or more variables that can be determined to be either true or false. In a database, a table (relation) is the representation of a logical predicate; it represents the complete set of all facts (propositions) that make the predicate true.\n",
        "\n",
        "2. **Tuples and Truth**: Each **row (tuple)** is a specific set of attribute values that asserts a true proposition for the predicate. For example, if a table's predicate is \"Employee $x$ works on Project $y$,\" the row (Alice, P1) asserts the truth: \"Employee Alice works on Project P1.\"\n",
        "\n",
        "### The Normalization Link: Derivability and Integrity\n",
        "The power of predicate calculus is the ability to **derive new true propositions** from a minimal set of existing true propositions using rules of inference (which correspond to relational operations like **projectino** or **join**). Normalization frames the database design choice this way:\n",
        "\n",
        "**The Design Goal**: Decide **which predicates should become base relations (stored tables)** so that:\n",
        "* All other valid true propositions (facts) can be **most easily and efficiently derived** through relational operations.\n",
        "* The total number of stored facts is minimized to reduce redundancy.\n",
        "* The chance of making mistakes in creating true propositions (data anomalies) is minimized.\n",
        "\n",
        "**Attributes are subject to functional dependencies:** some attributes determine the values of others. Normalization ensures well-designed relations avoid storing data with tangled functional dependencies.\n",
        "\n",
        "Mathematical normalization is founded on the Closed World Assumption (CWA) [@10.1145/320107.32010]. The CWA is the assumption that the only facts that are true are those that are explicitly stated in the database. Facts that are not stated in the database are assumed to be false: If a student enrollment is missing from the database, we assume that the student is not enrolled in that course. This is a simplifying assumption that allows us to reason about the data in the database in a more precise way.\n",
        "\n",
        "This is an abstract, mathematical approach that requires reasoning about attribute-level dependencies independent of real-world entities.\n",
        "\n",
        "### Functional Dependencies\n",
        "\n",
        "The core concept is the **functional dependency**: attribute `A` functionally determines attribute `B` (written `A → B`) if knowing the value of `A` allows you to determine the unique value of `B`.\n",
        "\n",
        "**Examples:**\n",
        "- `student_id → student_name` (student ID determines the student's name)\n",
        "- `course_id → course_title` (course ID determines the course title)\n",
        "- `(student_id, course_id) → grade` (student + course determines the grade)\n",
        "\n",
        "The classical normal forms form a progression, each building on the previous one and addressing specific types of problematic functional dependencies. Let's examine each with examples.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Why Normalization Matters\n",
        "\n",
        "Poor database design leads to serious problems:\n",
        "\n",
        "1. **Update Anomalies**: When the same data is stored in multiple places, updates must be made in all locations or inconsistencies arise\n",
        "2. **Insertion Anomalies**: Cannot add certain data without having other, unrelated data present\n",
        "3. **Deletion Anomalies**: Deleting one piece of information inadvertently removes other important data\n",
        "4. **Data Redundancy**: Unnecessary duplication wastes storage and creates maintenance overhead\n",
        "\n",
        "**Example of unnormalized data:**\n",
        "\n",
        "```\n",
        "Employee Project Table (BAD DESIGN)\n",
        "┌─────────────┬──────────┬────────────┬─────────────┬──────────────┐\n",
        "│ project_id* │ emp_name │ dept_name  │ dept_phone  │ project_name │\n",
        "├─────────────┼──────────┼────────────┼─────────────┼──────────────┤\n",
        "│ P1          │ Alice    │ Engineering│ 555-0100    │ Database     │\n",
        "│ P2          │ Alice    │ Engineering│ 555-0100    │ API          │\n",
        "│ P3          │ Bob      │ Sales      │ 555-0200    │ Marketing    │\n",
        "└─────────────┴──────────┴────────────┴─────────────┴──────────────┘\n",
        "\n",
        "Problems:\n",
        "- Alice's department info is duplicated (redundancy)\n",
        "- If department phone changes, must update multiple rows (update anomaly)\n",
        "- Cannot add a department without a project (insertion anomaly)\n",
        "- Deleting last project removes department info (deletion anomaly)\n",
        "```\n",
        "\n",
        "Normalization solves these problems by organizing data into well-structured tables. In the mathematical approach, good design is defined through well-behaved functional dependencies in each table as described by the \"normal forms\".\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### First Normal Form (1NF)\n",
        "\n",
        "**Definition**: All attributes must contain **atomic (indivisible) values**. No repeating groups or arrays.\n",
        "\n",
        "**Problem**: Non-atomic values make it difficult to query specific items and violate the relational model's requirement that each cell contains a single value.\n",
        "\n",
        "**Example - Violation of 1NF:**\n",
        "\n",
        "```\n",
        "Student Course Registration (VIOLATES 1NF)\n",
        "┌─────────────┬──────────┬─────────────────────────┐\n",
        "│ student_id* │ name     │ courses                 │\n",
        "├─────────────┼──────────┼─────────────────────────┤\n",
        "│ 1           │ Alice    │ Math, Physics, Chemistry│  ← Non-atomic!\n",
        "│ 2           │ Bob      │ Physics, Biology        │  ← Non-atomic!\n",
        "└─────────────┴──────────┴─────────────────────────┘\n",
        "\n",
        "Student Course Registration (VIOLATES 1NF)\n",
        "┌─────────────┬──────────┬──────────┬─────────┬──────────┐\n",
        "│ student_id* │ name     │ course1  | course2 | course3  │\n",
        "├─────────────┼──────────┼──────────┼─────────┼──────────┤\n",
        "│ 1           │ Alice    │ Math     | Physics | Chemistry│  ← Repeated groups\n",
        "│ 2           │ Bob      │ Physics  | Biology │ NULL     │\n",
        "└─────────────┴──────────┴──────────┴─────────┴──────────┘\n",
        "\n",
        "\n",
        "Problem: Cannot easily query \"who is taking Physics?\"\n",
        "```\n",
        "\n",
        "**Normalized to 1NF:**\n",
        "\n",
        "```\n",
        "Student table:               Enrollment table:\n",
        "┌─────────────┬──────────┐   ┌─────────────┬───────────┐\n",
        "│ student_id* │ name     │   │ student_id* │ course*   │\n",
        "├─────────────┼──────────┤   ├─────────────┼───────────┤\n",
        "│ 1           │ Alice    │   │ 1           │ Math      │\n",
        "│ 2           │ Bob      │   │ 1           │ Physics   │\n",
        "└─────────────┴──────────┘   │ 1           │ Chemistry │\n",
        "                             │ 2           │ Physics   │\n",
        "                             │ 2           │ Biology   │\n",
        "                             └─────────────┴───────────┘\n",
        "```\n",
        "\n",
        "Now each cell contains a single atomic value, and queries are straightforward.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Second Normal Form (2NF)\n",
        "\n",
        "**Definition**: Must be in 1NF, and all non-key attributes must depend on the **entire primary key**, not just part of it.\n",
        "\n",
        "This only applies to tables with **composite primary keys** (multiple columns). It addresses **partial dependencies**.\n",
        "\n",
        "**Problem**: When non-key attributes depend on only part of the composite key, you get redundancy and update anomalies.\n",
        "\n",
        "**Example - Violation of 2NF:**\n",
        "\n",
        "```\n",
        "Enrollment table with composite key (student_id, course_id)\n",
        "┌────────────┬───────────┬──────────────┬──────────────┬───────────────┐\n",
        "│student_id* │course_id* │ student_name │ student_email│ course_title  │\n",
        "├────────────┼───────────┼──────────────┼──────────────┼───────────────┤\n",
        "│ 1          │ CS101     │ Alice        │ a@edu.com    │ Databases     │\n",
        "│ 1          │ CS102     │ Alice        │ a@edu.com    │ Algorithms    │ ← Redundant!\n",
        "│ 2          │ CS101     │ Bob          │ b@edu.com    │ Databases     │ ← Redundant!\n",
        "└────────────┴───────────┴──────────────┴──────────────┴───────────────┘\n",
        "\n",
        "Problems:\n",
        "- student_name depends only on student_id (partial dependency)\n",
        "- student_email depends only on student_id (partial dependency)\n",
        "- course_title depends only on course_id (partial dependency)\n",
        "- Redundancy: Alice's info repeated, \"Databases\" title repeated\n",
        "- Update anomaly: Changing Alice's email requires multiple updates\n",
        "```\n",
        "\n",
        "**Normalized to 2NF:**\n",
        "\n",
        "```\n",
        "Student table:                Course table:              Enrollment table:\n",
        "┌────────────┬──────┬───────┐ ┌───────────┬──────────┐ ┌────────────┬───────────┐\n",
        "│student_id* │ name │ email │ │course_id* │ title    │ │ student_id*│ course_id*│\n",
        "├────────────┼──────┼───────┤ ├───────────┼──────────┤ ├────────────┼───────────┤\n",
        "│ 1          │ Alice│ a@edu │ │ CS101     │ Databases│ │ 1          │ CS101     │\n",
        "│ 2          │ Bob  │ b@edu │ │ CS102     │ Algos    │ │ 1          │ CS102     │\n",
        "└────────────┴──────┴───────┘ └───────────┴──────────┘ │ 2          │ CS101     │\n",
        "                                                       └────────────┴───────────┘\n",
        "```\n",
        "\n",
        "Now each attribute depends on the entire primary key of its table. No redundancy, no partial dependencies.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Third Normal Form (3NF)\n",
        "\n",
        "**Definition**: Must be in 2NF, and no non-key attribute can depend on another non-key attribute. Eliminates **transitive dependencies**.\n",
        "\n",
        "**Problem**: When attribute A depends on the primary key, and attribute B depends on A (not directly on the key), you have a transitive dependency: `PK → A → B`.\n",
        "\n",
        "**Example - Violation of 3NF:**\n",
        "\n",
        "```\n",
        "Student table\n",
        "┌────────────┬──────────┬─────────────┬────────────┬──────────────┐\n",
        "│*student_id │ name     │ department  │ dept_name  │ dept_building│\n",
        "├────────────┼──────────┼─────────────┼────────────┼──────────────┤\n",
        "│ 1          │ Alice    │ CS          │ Comp Sci   │ Building A   │\n",
        "│ 2          │ Bob      │ CS          │ Comp Sci   │ Building A   │ ← Redundant!\n",
        "│ 3          │ Carol    │ MATH        │ Mathematics│ Building B   │\n",
        "│ 4          │ Dave     │ CS          │ Comp Sci   │ Building A   │ ← Redundant!\n",
        "└────────────┴──────────┴─────────────┴────────────┴──────────────┘\n",
        "\n",
        "Problems:\n",
        "- dept_name depends on department, not directly on student_id\n",
        "- dept_building depends on department, not directly on student_id\n",
        "- Transitive dependency: student_id → department → dept_name\n",
        "- Redundancy: CS department info repeated three times\n",
        "- Update anomaly: If CS department moves buildings, must update multiple rows\n",
        "- Deletion anomaly: If all CS students leave, we lose CS department info\n",
        "```\n",
        "\n",
        "**Normalized to 3NF:**\n",
        "\n",
        "```\n",
        "Student table:                    Department table:\n",
        "┌────────────┬──────┬────────┐   ┌─────────────┬─────────┬──────────┐\n",
        "│student_id* │ name │ dept   │   │ dept_code*  │ name    │ building │\n",
        "├────────────┼──────┼────────┤   ├─────────────┼─────────┼──────────┤\n",
        "│ 1          │ Alice│ CS     │   │ CS          │ Comp Sci│ Bldg A   │\n",
        "│ 2          │ Bob  │ CS     │   │ MATH        │ Math    │ Bldg B   │\n",
        "│ 3          │ Carol│ MATH   │   └─────────────┴─────────┴──────────┘\n",
        "│ 4          │ Dave │ CS     │\n",
        "└────────────┴──────┴────────┘\n",
        "```\n",
        "\n",
        "Now department information is stored once, and there are no transitive dependencies. Each attribute directly depends on its table's primary key.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Mathematical Normalization: Abstract and Rigorous\n",
        "\n",
        "**The famous mnemonic**: \"Every non-key attribute must depend on the key, the whole key, and nothing but the key --- and so help me... Codd.\"\n",
        "\n",
        "**Characteristics:**\n",
        "- **Abstract**: Reasons about predicates and functional dependencies, not real-world entities\n",
        "- **Mathematical**: Provides formal, rigorous definitions and proofs\n",
        "- **Attribute-centric**: Focuses on relationships between attributes\n",
        "- **Prescriptive**: Provides clear rules (normal forms) to check compliance\n",
        "\n",
        "**Strengths:**\n",
        "- Mathematically rigorous and provably correct\n",
        "- Provides precise definitions of what constitutes a \"problem\"\n",
        "- Forms the theoretical foundation of database design\n",
        "- Can be mechanically checked and verified\n",
        "\n",
        "**Limitations:**\n",
        "- Requires identifying all functional dependencies (complex in practice)\n",
        "- Doesn't naturally map to how people think about domains\n",
        "- Provides little guidance on how to initially decompose a domain\n",
        "- Abstract nature makes it less accessible for practitioners\n",
        "\n",
        "**Key insight**: Mathematical normalization provides rigor but requires thinking in terms of attribute dependencies rather than the entities and processes we intuitively recognize in our domains."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Approach 2: Entity Normalization\n",
        "\n",
        "In 1976, Peter Chen introduced the Entity-Relationship Model [@10.1145/320434.320440], which revolutionized how we think about database design. Rather than starting with predicates, attributes, and functional dependencies, Chen proposed starting with **entities** and **relationships**.\n",
        "\n",
        "### The Entity-Centric Foundation\n",
        "\n",
        "In Chen's ERM:\n",
        "- **Entities are things of interest**: Real-world objects or concepts we want to store information about\n",
        "- **Entity types have instances**: Each entity type (e.g., Student, Course) has many instances (specific students, specific courses)\n",
        "- **Attributes describe entities**: Properties that characterize entity instances\n",
        "- **Relationships connect entities**: Associations between entity types (e.g., Student enrolls in Course)\n",
        "\n",
        "This is a **concrete, applied approach** that starts with recognizing entities in your domain and then determining their properties.\n",
        "\n",
        "### The Entity Normalization Principle\n",
        "\n",
        "> **Each table represents exactly one well-defined entity type, identified by the table's primary key. All non-key attributes must describe that entity type directly, completely, and non-optionally.**\n",
        "\n",
        "This principle translates into three practical rules:\n",
        "\n",
        "#### Rule 1: One Entity Type Per Table\n",
        "\n",
        "Each table must represent a single, well-defined entity type. The primary key identifies instances of that entity type.\n",
        "\n",
        "**Questions to ask:**\n",
        "- What entity type does this table represent?\n",
        "- Does the primary key uniquely identify instances of this entity type?\n",
        "- Are all rows instances of the same entity type?\n",
        "\n",
        "#### Rule 2: Attributes Describe the Entity Directly\n",
        "\n",
        "Every non-key attribute must be a property **of the entity identified by the primary key**, not a property of some other entity.\n",
        "\n",
        "**Questions to ask:**\n",
        "- Is this attribute a property of the entity identified by the primary key?\n",
        "- Or is it actually a property of a different entity type?\n",
        "- Can this attribute be determined from the primary key alone?\n",
        "\n",
        "#### Rule 3: No Transitive or Partial Dependencies\n",
        "\n",
        "All non-key attributes must depend on:\n",
        "- **The entire primary key** (not just part of it) — eliminates partial dependencies\n",
        "- **Directly on the primary key** (not through another attribute) — eliminates transitive dependencies\n",
        "- **Non-optionally** — eliminates optional dependencies that suggest multiple entity types\n",
        "\n",
        "**Questions to ask:**\n",
        "- Does this attribute depend on the entire primary key or just part of it?\n",
        "- Does this attribute depend directly on the primary key, or through another attribute?\n",
        "- Is this attribute always present, or only for certain instances?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Entity Normalization in Practice\n",
        "\n",
        "Let's revisit the earlier examples through the lens of entity normalization:\n",
        "\n",
        "**Example 1: Student enrollments with courses as a list**\n",
        "\n",
        "From an entity perspective:\n",
        "- **What entity types exist?** Students, Courses, and Enrollments (the relationship between students and courses)\n",
        "- **Problem**: The first design tries to store multiple entity types (courses) within a single attribute\n",
        "- **Solution**: Recognize Enrollment as its own entity type, with each instance representing one student enrolled in one course\n",
        "\n",
        "**Example 2: Enrollment with student and course attributes**\n",
        "\n",
        "From an entity perspective:\n",
        "- **What entity types exist?** Students, Courses, and Enrollments\n",
        "- **Problem**: The Enrollment table contains attributes that describe **other entity types** (student_name describes Student, course_title describes Course)\n",
        "- **Question**: \"Is student_name a property of an Enrollment?\" No, it's a property of a Student.\n",
        "- **Solution**: Separate Student and Course into their own tables. Enrollment references them via foreign keys.\n",
        "\n",
        "**Example 3: Student with department information**\n",
        "\n",
        "From an entity perspective:\n",
        "- **What entity types exist?** Students and Departments\n",
        "- **Problem**: The Student table contains attributes that describe a **different entity type** (dept_name and dept_building describe Department, not Student)\n",
        "- **Question**: \"Is dept_building a property of a Student?\" No, it's a property of the student's Department.\n",
        "- **Solution**: Separate Department into its own table. Student references Department via foreign key.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Relationship Sets as Entity Types\n",
        "\n",
        "An important insight from ERM: **relationships themselves can be analyzed similarly to entity types**. When a many-to-many relationship has attributes, it should be modeled as its own table.\n",
        "\n",
        "**Example: Student-Course Enrollment with Grade**\n",
        "\n",
        "```\n",
        "┌─────────────┬───────────┬───────┐\n",
        "│ student_id* │ course_id*│ grade │  ← Enrollment is an entity type!\n",
        "├─────────────┼───────────┼───────┤\n",
        "│ 1           │ CS101     │ A     │\n",
        "│ 1           │ CS102     │ B     │\n",
        "│ 2           │ CS101     │ A-    │\n",
        "└─────────────┴───────────┴───────┘\n",
        "```\n",
        "\n",
        "**Entity perspective:**\n",
        "- **Entity type**: Enrollment (not just a relationship)\n",
        "- **Entity instances**: Each row represents one specific enrollment event\n",
        "- **Primary key**: (student_id, course_id) identifies each enrollment instance\n",
        "- **Attributes**: grade describes this enrollment, not the student or the course\n",
        "\n",
        "**Normalization criteria for relationship sets:**\n",
        "- ✅ Represents one well-defined entity type (Enrollments)\n",
        "- ✅ Attributes describe the relationship entity directly (grade is a property of the enrollment)\n",
        "- ✅ All attributes depend on the entire key (grade depends on both student AND course)\n",
        "- ✅ No attributes describe the related entities (no student_name or course_title)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Entity Normalization Leads to Similar Design as Mathematical Normalization\n",
        "\n",
        "**The key insight**: While entity normalization uses different reasoning (entity types rather than functional dependencies), it **leads to the same design principles** as the mathematical normal forms:\n",
        "\n",
        "| Mathematical View | Entity View | Result |\n",
        "|-----------------|-------------|---------|\n",
        "| 1NF: No repeating groups | Each row represents one entity instance | Separate tables for different entity types |\n",
        "| 2NF: No partial dependencies | Attributes depend on the entire entity identity | All attributes describe the complete entity |\n",
        "| 3NF: No transitive dependencies | Attributes describe this entity, not others | Foreign keys reference other entity types |\n",
        "\n",
        "**The difference in approach:**\n",
        "- **Mathematical**: Start with a table, identify functional dependencies, decompose to eliminate violations\n",
        "- **Entity**: Start by identifying entity types, create one table per entity type, ensure attributes describe only that entity\n",
        "\n",
        "**The advantage of entity normalization**: It's more intuitive and aligns with how people naturally conceptualize domains. Instead of analyzing abstract dependencies, you ask concrete questions: \"What entities exist? What are their properties?\"\n",
        "\n",
        "### The Entity Approach: Applied and Intuitive\n",
        "\n",
        "**Characteristics:**\n",
        "- **Concrete**: Starts with recognizable entities in the domain\n",
        "- **Intuitive**: Maps to how people naturally think about their domain\n",
        "- **Entity-centric**: Focuses on identifying entity types and their properties\n",
        "- **Constructive**: Provides guidance on how to decompose a domain\n",
        "\n",
        "**Strengths:**\n",
        "- Natural mapping to domain understanding\n",
        "- Easier for practitioners to apply\n",
        "- Provides clear starting point (identify entities)\n",
        "- Leads to the same rigorous results as mathematical normalization\n",
        "\n",
        "**Limitations:**\n",
        "- Less formally rigorous than functional dependency analysis\n",
        "- Requires good domain understanding\n",
        "- Can be ambiguous what constitutes an \"entity type\"\n",
        "- Doesn't naturally address temporal aspects (when entities are created)\n",
        "\n",
        "**Key insight**: Entity normalization achieves the same goals as mathematical normalization but through more accessible reasoning about entity types and their properties.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Approach 3: Workflow Normalization\n",
        "\n",
        "DataJoint extends entity normalization with a sequential dimension: the **Entity-Workflow Model** [@10.48550/arXiv.1807.11104]. While traditional ERM focuses on **what entities exist** and how they relate to each other, DataJoint emphasizes **when and how entities are created** through workflow execution. \n",
        "Foreign keys not only define referential integrity, but also prescribe the order of operations.\n",
        "\n",
        "### The Workflow-Centric Foundation\n",
        "\n",
        "DataJoint builds on Chen's ERM but adds a critical dimension:\n",
        "\n",
        "**Tradiitional ERM:**\n",
        "- **Entities are things that exist**: Objects in the domain\n",
        "- **Focus on current state**: What properties does this entity have?\n",
        "- **Relationships are static**: Associations between entity types\n",
        "- **Design question**: What entities exist in my domain? How do they relate to each other?\n",
        "\n",
        "**DataJoint's Entity-Workflow Model:**\n",
        "- **Entities are artifacts created by operations**: Products of workflow execution\n",
        "- **Focus on workflow sequence**: When/how is this entity created?\n",
        "- **Relationships are workflow dependencies**: Operations must execute in order\n",
        "- **Design question**: What workflow steps create what entities?\n",
        "\n",
        "This is a **temporal, operational approach** that views the database schema as a workflow diagram where foreign keys define the valid order of operations.\n",
        "\n",
        "### The Workflow Normalization Principle\n",
        "\n",
        "> **Every table represents an entity type that is created at a specific step in a workflow, and all attributes describe that entity as it exists at that workflow step.**\n",
        "\n",
        "**Key additions to entity normalization:**\n",
        "- **Foreign keys define operation order**: Parent must be populated before child\n",
        "- **Schema is a directed acyclic graph (DAG)**: Represents valid workflow sequences\n",
        "- **Entities created at different times are separate**: Even if conceptually related\n",
        "\n",
        "This principle leads to three practical rules for workflow-based normalization:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Rule 1: One Workflow Step Per Table\n",
        "\n",
        "Each table represents exactly one step in a workflow where entities are created. Don't mix different workflow steps in the same table.\n",
        "\n",
        "**Questions to ask:**\n",
        "- What workflow step does this table represent?\n",
        "- Are all rows created at the same stage of the workflow?\n",
        "- What operation creates entities in this table?\n",
        "\n",
        "### Rule 2: Attributes Describe Only That Workflow Entity\n",
        "\n",
        "Every attribute must describe the entity as it exists at this specific workflow step, not properties from other workflow steps.\n",
        "\n",
        "**Questions to ask:**\n",
        "- Does this attribute describe the entity at this workflow step?\n",
        "- Would this attribute be available when this workflow step executes?\n",
        "- Is this a property of THIS workflow entity or from a different workflow step?\n",
        "\n",
        "### Rule 3: Separate Entities by Workflow Steps\n",
        "\n",
        "Model each workflow step as a separate table. Entities that are created at different workflow steps should be in different tables, even if they represent the same conceptual entity.\n",
        "\n",
        "**Questions to ask:**\n",
        "- At which workflow step is this entity created?\n",
        "- What are the valid sequences of operations that lead to this entity?\n",
        "- Does this entity depend on the completion of other workflow steps?\n",
        "\n",
        "**Decision rule:**\n",
        "- **Same workflow step** → Include in same table (e.g., `Mouse` properties all created during mouse registration)\n",
        "- **Different workflow steps** → Create separate tables (e.g., `RawRecording` → `FilteredRecording` → `SpikeSorting`)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Foreign Keys as Workflow Dependencies\n",
        "\n",
        "In workflow normalization, foreign keys have a **dual role**:\n",
        "\n",
        "1. **Referential integrity** (like traditional databases): Child references must exist in parent\n",
        "2. **Workflow dependency** (DataJoint addition): Parent must be created before child\n",
        "\n",
        "This transforms the schema into a **directed acyclic graph (DAG)** representing valid workflow execution sequences.\n",
        "\n",
        "**Example: Data Processing Pipeline**\n",
        "\n",
        "```\n",
        "RawImage                    ← Step 1: Acquire raw image\n",
        "    ↓ (foreign key)\n",
        "PreprocessedImage          ← Step 2: Preprocess (depends on RawImage)\n",
        "    ↓ (foreign key)\n",
        "SegmentedCells            ← Step 3: Segment (depends on PreprocessedImage)\n",
        "    ↓ (foreign key)  \n",
        "CellStatistics           ← Step 4: Analyze (depends on SegmentedCells)\n",
        "```\n",
        "\n",
        "**Workflow interpretation:**\n",
        "- Can't preprocess before acquiring raw image\n",
        "- Can't segment before preprocessing\n",
        "- Can't analyze before segmentation\n",
        "- Schema defines the **valid order of operations**\n",
        "\n",
        "**Cyclic dependencies are prohibited**: Would create logical contradictions in workflow execution (A must happen before B, but B must happen before A).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### The Schema as Workflow Diagram\n",
        "\n",
        "The Entity-Workflow Model views the database schema itself as a **workflow diagram**:\n",
        "\n",
        "- **Nodes (tables)**: Workflow steps that create entity types\n",
        "- **Edges (foreign keys)**: Workflow dependencies and valid operation sequences\n",
        "- **DAG structure**: Guarantees workflows can execute without circular dependencies\n",
        "\n",
        "**Example: Neuroscience Workflow**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Workflow Normalization vs. Entity Normalization\n",
        "\n",
        "**Where workflow normalization extends entity normalization:**\n",
        "\n",
        "Entity normalization would accept this design:\n",
        "\n",
        "```python\n",
        "# Entity perspective: One table per entity type\n",
        "@schema\n",
        "class Mouse(dj.Manual):\n",
        "    definition = \"\"\"\n",
        "    mouse_id : int\n",
        "    ---\n",
        "    date_of_birth : date          # ✓ Property of mouse\n",
        "    sex : enum('M', 'F')          # ✓ Property of mouse\n",
        "    genotype : varchar(100)       # ✓ Property of mouse - determined after sequencing\n",
        "    weight : decimal(5,2)         # ✓ Property of mouse - measured value\n",
        "    \"\"\"\n",
        "```\n",
        "\n",
        "**Entity normalization says:** \"This represents one entity type (Mouse) with its properties.\"\n",
        "\n",
        "**Workflow normalization asks:** \"When is each attribute created?\"\n",
        "- `date_of_birth`, `sex` are created at mouse registration (workflow step 1)\n",
        "- `genotype` is created after genetic sequencing (workflow step 2)  \n",
        "- `weight` is measured at various times (workflow step 3, repeatable)\n",
        "\n",
        "**Workflow normalization requires:**\n",
        "\n",
        "```python\n",
        "# Workflow perspective: Separate tables for separate workflow steps\n",
        "@schema\n",
        "class Mouse(dj.Manual):\n",
        "    definition = \"\"\"\n",
        "    mouse_id : int\n",
        "    ---\n",
        "    date_of_birth : date          # Created at registration\n",
        "    sex : enum('M', 'F')          # Created at registration\n",
        "    \"\"\"\n",
        "\n",
        "@schema\n",
        "class GeneticSequencing(dj.Manual):\n",
        "    definition = \"\"\"\n",
        "    -> Mouse                       # Depends on mouse existing\n",
        "    ---\n",
        "    genotype : varchar(100)        # Created by sequencing operation\n",
        "    sequencing_date : date\n",
        "    \"\"\"\n",
        "\n",
        "@schema\n",
        "class WeightMeasurement(dj.Manual):\n",
        "    definition = \"\"\"\n",
        "    -> Mouse                       # Depends on mouse existing\n",
        "    measurement_date : date        # Part of key - repeatable operation\n",
        "    ---\n",
        "    weight : decimal(5,2)         # Created by measurement operation\n",
        "    \"\"\"\n",
        "```\n",
        "\n",
        "**Why this matters:**\n",
        "- **Workflow dependencies are explicit**: Can't sequence before mouse exists\n",
        "- **Temporal order is enforced**: Foreign keys define operation sequence\n",
        "- **Schema is a DAG**: No circular dependencies, represents valid workflows\n",
        "- **Updates are avoided**: Each workflow step creates immutable artifacts\n",
        "- **Data populated at different times are separate**: Each workflow step has its own table\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Why Workflow Normalization is Stricter\n",
        "\n",
        "**Key insight**: Workflow normalization enforces temporal separation that entity normalization doesn't require. A table can be perfectly normalized under mathematical and entity normalization yet still violate workflow normalization principles.\n",
        "\n",
        "**Example: E-commerce Order Processing**\n",
        "\n",
        "Consider an Order table that tracks the complete lifecycle of an order:\n",
        "\n",
        "```\n",
        "Order table\n",
        "┌──────────┬──────────────┬──────────────┬────────────────┬───────────────┬──────────────┬────────────────┐\n",
        "│order_id* │ product_id   │ customer_id  │ payment_method │ payment_date  │ shipment_date│ delivery_date  │\n",
        "├──────────┼──────────────┼──────────────┼────────────────┼───────────────┼──────────────┼────────────────┤\n",
        "│ 1001     │ WIDGET-A     │ C0137        │ Credit Card    │ 2024-10-16    │ 2024-10-18   │ 2024-10-20     │\n",
        "│ 1002     │ GADGET-B     │ C0173        │ PayPal         │ 2024-10-17    │ NULL         │ NULL           │\n",
        "│ 1003     │ TOOL-C       │ C3310        │ NULL           │ NULL          │ NULL         │ NULL           │\n",
        "└──────────┴──────────────┴──────────────┴────────────────┴───────────────┴──────────────┴────────────────┘\n",
        "```\n",
        "\n",
        "**Mathematical normalization analysis:**\n",
        "- ✅ **1NF**: All attributes are atomic\n",
        "- ✅ **2NF**: No composite key, so no partial dependencies\n",
        "- ✅ **3NF**: All non-key attributes depend directly on `order_id`\n",
        "\n",
        "**Verdict**: Perfectly normalized!\n",
        "\n",
        "**Entity normalization analysis:**\n",
        "- **What entity type does this represent?** An Order\n",
        "- **Do all attributes describe the order?** Yes—payment details, shipment details, delivery details are all properties of this order\n",
        "- ✅ All attributes describe the Order entity\n",
        "- ✅ No transitive dependencies through other entity types\n",
        "\n",
        "**Verdict**: Perfectly normalized!\n",
        "\n",
        "**Workflow normalization analysis:**\n",
        "- **When is each attribute created?**\n",
        "  - `product_id`: When order is **placed** (workflow step 1)\n",
        "  - `payment_date`, `payment_method`: When payment is **processed** (workflow step 2)\n",
        "  - `shipment_date`: When order is **shipped** (workflow step 3)\n",
        "  - `delivery_date`: When order is **delivered** (workflow step 4)\n",
        "\n",
        "**Problems identified:**\n",
        "1. **Mixes workflow steps**: Table contains data created at four different times\n",
        "2. **Temporal sequence not enforced**: Nothing prevents `shipment_date` before `payment_date`\n",
        "3. **NULLs indicate incomplete workflow**: Row 1003 has many NULLs because workflow hasn't progressed\n",
        "4. **Requires UPDATEs**: As workflow progresses, must UPDATE the row multiple times\n",
        "5. **Incompleteness**: Nullable attributes allow entering shipment without payment\n",
        "6. **No workflow dependencies**: Database doesn't enforce the order of operations: payment must precede shipment\n",
        "\n",
        "**Workflow normalization requires the following design:**\n",
        "\n",
        "```python\n",
        "@schema\n",
        "class Order(dj.Manual):\n",
        "    definition = \"\"\"\n",
        "    order_id : int\n",
        "    order_date : datetime\n",
        "    ---\n",
        "    -> Product\n",
        "    -> Customer\n",
        "    \"\"\"\n",
        "\n",
        "@schema\n",
        "class Payment(dj.Manual):\n",
        "    definition = \"\"\"\n",
        "    -> Order                       # Can't pay before ordering\n",
        "    ---\n",
        "    payment_date : datetime\n",
        "    payment_method : enum('Credit Card', 'PayPal', 'Bank Transfer')\n",
        "    amount : decimal(10,2)\n",
        "    \"\"\"\n",
        "\n",
        "@schema\n",
        "class Shipment(dj.Manual):\n",
        "    definition = \"\"\"\n",
        "    -> Payment                     # Can't ship before payment\n",
        "    ---\n",
        "    shipment_date : date       # all attributes are requires (non-nullable)\n",
        "    carrier : varchar(50)\n",
        "    tracking_number : varchar(100)\n",
        "    \"\"\"\n",
        "\n",
        "@schema\n",
        "class Delivery(dj.Manual):\n",
        "    definition = \"\"\"\n",
        "    -> Shipment                    # Can't deliver before shipping\n",
        "    ---\n",
        "    delivery_date : datetime\n",
        "    recipient_signature : varchar(100)\n",
        "    \"\"\"\n",
        "\n",
        "@schema  \n",
        "class DeliveryConfirmation(dj.Manual):\n",
        "    definition = \"\"\"\n",
        "    -> Delivery                    # Can't confirm before delivery\n",
        "    ---\n",
        "    confirmation_date : datetime\n",
        "    confirmation_method : enum('Email', 'SMS', 'App')\n",
        "    \"\"\"\n",
        "```\n",
        "\n",
        "**Workflow structure (enforced by foreign keys):**\n",
        "\n",
        "```\n",
        "Order                        ← Step 1: Customer places order\n",
        "    ↓ (must exist before payment)\n",
        "Payment                      ← Step 2: Payment processed\n",
        "    ↓ (must exist before shipment)\n",
        "Shipment                     ← Step 3: Order shipped\n",
        "    ↓ (must exist before delivery)\n",
        "Delivery                     ← Step 4: Order delivered\n",
        "    ↓ (must exist before confirmation)\n",
        "DeliveryConfirmation        ← Step 5: Delivery confirmed\n",
        "```\n",
        "\n",
        "**Why this is better:**\n",
        "\n",
        "1. ✅ **Workflow sequence enforced**: Database prevents shipment before payment\n",
        "2. ✅ **No NULLs**: Each table only exists when its workflow step completes\n",
        "3. ✅ **Immutable artifacts**: Each workflow step creates permanent record\n",
        "4. ✅ **Complete history**: Can see exactly when each step occurred\n",
        "5. ✅ **No UPDATE needed**: Workflow progression is INSERT operations\n",
        "6. ✅ **Explicit dependencies**: Schema IS the workflow diagram\n",
        "7. ✅ **Workflow state query**: \"Show all paid-but-not-shipped orders\" = `Payment - Shipment`\n",
        "\n",
        "**This demonstrates**: Workflow normalization is **stricter** than mathematical or entity normalization. It requires separating data not just by entity type or functional dependencies, but by **when and how that data is created** in the workflow.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example: Neuroscience Workflow\n",
        "\n",
        "Consider a typical neuroscience workflow where entities are created at each step:\n",
        "\n",
        "```\n",
        "Session                    ← Workflow Step 1: Experimenter creates session entities\n",
        "    ↓ (workflow dependency)\n",
        "Recording                  ← Workflow Step 2: Data acquisition creates recording entities\n",
        "    ↓ (workflow dependency)\n",
        "FilteredRecording         ← Workflow Step 3: Filtering creates filtered recording entities\n",
        "    ↓ (workflow dependency)\n",
        "SpikeSorting              ← Workflow Step 4: Spike detection creates sorting entities\n",
        "    ↓ (workflow dependency)\n",
        "NeuronStatistics          ← Workflow Step 5: Analysis creates statistics entities\n",
        "```\n",
        "\n",
        "**Each workflow step creates new entities:**\n",
        "- `Session` entities are created by experimenter input\n",
        "- `Recording` entities are created by data acquisition from sessions\n",
        "- `FilteredRecording` entities are created by filtering operations on recordings\n",
        "- `SpikeSorting` entities are created by spike detection on filtered recordings\n",
        "- `NeuronStatistics` entities are created by analysis on spike sorting results\n",
        "\n",
        "**Critical insight**: Each table represents entities created at a specific workflow step, and foreign keys represent the valid sequences of operations that create these entities.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Why Updates Break Workflow Execution\n",
        "\n",
        "In the Entity-Workflow Model, **updates to upstream entities silently invalidate downstream workflow artifacts**:\n",
        "\n",
        "**Scenario**: You discover the sampling rate in `Recording` for `{'session': 42}` was recorded incorrectly.\n",
        "\n",
        "**If you UPDATE:**\n",
        "```python\n",
        "# Fix the sampling rate\n",
        "Recording.update1({'session': 42, 'sampling_rate': 30000})  # Was 20000, should be 30000\n",
        "\n",
        "# But now:\n",
        "# - FilteredRecording(42) entities were created using sampling_rate=20000\n",
        "# - SpikeSorting(42) entities were created from FilteredRecording with wrong rate\n",
        "# - NeuronStatistics(42) entities were created from SpikeSorting with wrong rate\n",
        "#\n",
        "# All downstream workflow artifacts are INVALID, but the database doesn't know!\n",
        "# No error, no warning, no indication of the problem.\n",
        "# The entities exist but represent incorrect workflow execution.\n",
        "```\n",
        "\n",
        "**If you use DELETE (enforced by workflow model):**\n",
        "```python\n",
        "# Delete the incorrect recording entity\n",
        "(Recording & {'session': 42}).delete()\n",
        "# This cascades to delete all downstream workflow artifacts:\n",
        "# - FilteredRecording entities created from this recording\n",
        "# - SpikeSorting entities created from those filtered recordings\n",
        "# - NeuronStatistics entities created from those spike sortings\n",
        "\n",
        "# Reinsert with correct data\n",
        "Recording.insert1({'session': 42, 'sampling_rate': 30000, ...})\n",
        "\n",
        "# Re-execute workflow steps to create new entities\n",
        "FilteredRecording.populate({'session': 42})  # Creates new filtered recording entities\n",
        "SpikeSorting.populate({'session': 42})       # Creates new spike sorting entities\n",
        "NeuronStatistics.populate({'session': 42})   # Creates new statistics entities\n",
        "\n",
        "# Now ALL workflow artifacts are consistent and scientifically valid\n",
        "```\n",
        "\n",
        "The workflow execution sequence is **explicit** and **enforced**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Problems with this design:**\n",
        "\n",
        "1. **Mixes entity types**: Contains both mouse properties AND cage properties\n",
        "2. **Requires updates**: When a mouse moves cages or gains weight, we must UPDATE the row\n",
        "3. **Redundant data**: If multiple mice share a cage, cage location and capacity are duplicated\n",
        "4. **Loses history**: When a mouse moves or weight changes, old values are lost\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Why DataJoint Relies on INSERT and DELETE\n",
        "\n",
        "DataJoint provides the `update1()` method to update secondary attributes in an existing row, but it is intended for **surgical correction of data anomalies**—fixing errors that should not have occurred—not for regular data manipulation.\n",
        "\n",
        "#### UPDATE is Available But Not for Regular Operations\n",
        "\n",
        "The philosophy: if you find yourself using UPDATE frequently in normal workflows, it indicates a schema design  that does not match the operations of your enterprise.\n",
        "\n",
        "**When UPDATE is appropriate:**\n",
        "- ✅ Correcting data entry errors (e.g., mouse sex was recorded incorrectly) -- but only if it is known that none of the downstream data depends on the attribute that is being updated.\n",
        "\n",
        "In all other cases, it is more appropriate to delete the old record and to re-populate the downstream data from the primary data taking into account the updated attributes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Reason 1: Well-Normalized Schemas Don't Need Regular Updates\n",
        "\n",
        "In a properly normalized schema:\n",
        "- **Permanent attributes** never change (they're intrinsic to the entity)\n",
        "- **Time-varying attributes** are in separate tables (separate steps in the workflow), often with date/time in the primary key to preserve history.\n",
        "- \"Changing\" means adding new records (INSERT) or removing invalid ones (DELETE)\n",
        "\n",
        "**Example: Mouse Weight Over Time**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```python\n",
        "# ❌ Bad: Requires UPDATE for normal operations\n",
        "@schema\n",
        "class Mouse(dj.Manual):\n",
        "    definition = \"\"\"\n",
        "    mouse_id : int\n",
        "    ---\n",
        "    current_weight : decimal(5,2)  # Must UPDATE every time weight changes!\n",
        "    \"\"\"\n",
        "\n",
        "# Mouse weighs 25g today\n",
        "Mouse.insert1({'mouse_id': 1, 'current_weight': 25.0})\n",
        "# A week later, weighs 27g - requires UPDATE\n",
        "Mouse.update1({'mouse_id': 1, 'current_weight': 27.0})  # Loses history!\n",
        "```\n",
        "\n",
        "```python\n",
        "# ✅ Good: Uses INSERT for normal operations\n",
        "@schema\n",
        "class Mouse(dj.Manual):\n",
        "    definition = \"\"\"\n",
        "    mouse_id : int\n",
        "    ---\n",
        "    sex : enum('M', 'F')           # Permanent—never changes\n",
        "    date_of_birth : date           # Permanent—never changes\n",
        "    \"\"\"\n",
        "\n",
        "@schema\n",
        "class WeightMeasurement(dj.Manual):\n",
        "    definition = \"\"\"\n",
        "    -> Mouse\n",
        "    measurement_date : date        # Part of primary key to preserve history\n",
        "    ---\n",
        "    weight : decimal(5,2)\n",
        "    \"\"\"\n",
        "\n",
        "# Mouse weighs 25g today\n",
        "WeightMeasurement.insert1(\n",
        "    {'mouse_id': 1, 'measurement_date': '2024-01-01', 'weight': 25.0})\n",
        "# A week later, weighs 27g - just INSERT\n",
        "WeightMeasurement.insert1(\n",
        "    {'mouse_id': 1, 'measurement_date': '2024-01-08', 'weight': 27.0})\n",
        "# History preserved! Can see weight trajectory\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Reason 2: Foreign Keys Reference Complete Tuples\n",
        "\n",
        "Foreign keys establish relationships between **entire tuples**, not just ID columns:\n",
        "\n",
        "```python\n",
        "-> Mouse  # References the complete tuple: (mouse_id, sex, date_of_birth)\n",
        "```\n",
        "\n",
        "When you UPDATE an attribute in the parent tuple, you logically create a \"different\" tuple:\n",
        "- The foreign key constraint is still technically satisfied (the ID matches)\n",
        "- But the semantic relationship is broken (child references old values, parent has new values)\n",
        "- This violates referential integrity at the logical level\n",
        "\n",
        "**Example:**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```python\n",
        "# Mouse table\n",
        "Mouse.insert1({'mouse_id': 1, 'sex': 'M', 'date_of_birth': '2024-01-01'})\n",
        "\n",
        "# Experiment references this specific mouse\n",
        "Experiment.insert1({'experiment_id': 100, 'mouse_id': 1, 'date': '2024-06-01'})\n",
        "# Semantically: \"Experiment 100 was performed on the male mouse born 2024-01-01\"\n",
        "\n",
        "# Later, realize sex was recorded wrong - UPDATE\n",
        "Mouse.update1({'mouse_id': 1, 'sex': 'F'})\n",
        "# Now Experiment 100 references a different logical entity!\n",
        "# It claims to be on \"male mouse born 2024-01-01\" but that tuple no longer exists\n",
        "# The relationship is semantically broken, even though FK constraint is satisfied\n",
        "\n",
        "# DELETE makes this explicit:\n",
        "(Mouse & {'mouse_id': 1}).delete()  # Experiment references this mouse!\n",
        "# Cascades the delete to Experiment forces you to repopulate the dependent data\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Reason 3: Updates Bypass Data Dependency Checks\n",
        "\n",
        "In computational workflows, downstream data is derived from upstream data. UPDATE creates silent inconsistencies; DELETE makes dependencies explicit.\n",
        "\n",
        "**Example: Image Processing Pipeline**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```python\n",
        "\n",
        "# Pipeline: RawImage → PreprocessedImage → SegmentedCells → CellActivity\n",
        "\n",
        "# Original data and processing\n",
        "RawImage.insert1({'image_id': 42, 'brightness': 1.0, 'contrast': 1.0})\n",
        "PreprocessedImage.populate()  # Derives from RawImage(42) with brightness=1.0\n",
        "SegmentedCells.populate()     # Derives from PreprocessedImage(42)\n",
        "CellActivity.populate()       # Derives from SegmentedCells(42)\n",
        "\n",
        "# Discover image brightness was wrong - need to fix\n",
        "\n",
        "# ❌ Using UPDATE - silent inconsistency:\n",
        "RawImage.update1({'image_id': 42, 'brightness': 1.5})\n",
        "# No error! But...\n",
        "# - PreprocessedImage was computed with brightness=1.0\n",
        "# - SegmentedCells was computed from OLD preprocessed image\n",
        "# - CellActivity was computed from OLD segmentation\n",
        "# All downstream results are now invalid but database doesn't know!\n",
        "\n",
        "# ✅ Using DELETE - explicit dependency handling:\n",
        "(RawImage & {'image_id': 42}).delete()\n",
        "# This delete will cascade to the dependent tables for image_id=42, \n",
        "# in reverse order of dependency:\n",
        "# CellActivity \n",
        "# SegmentedCells\n",
        "# PreprocessedImage\n",
        "# RawImage\n",
        "\n",
        "# Now reinsert and recompute entire pipeline\n",
        "RawImage.insert1({'image_id': 42, 'brightness': 1.5, 'contrast': 1.0})\n",
        "PreprocessedImage.populate()  # Recomputes with correct brightness\n",
        "SegmentedCells.populate()     # Recomputes from new preprocessed image\n",
        "CellActivity.populate()       # Recomputes from new segmentation\n",
        "# All results are now consistent!\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### The Philosophy: Updates as a Design Smell\n",
        "\n",
        "**Key insight**: In a workflow-normalized schema, regular operations flow naturally through INSERT and DELETE alone. If you need UPDATE as part of normal workflows, it's a signal that:\n",
        "\n",
        "1. **Changeable attributes weren't separated** → Violates Rule 3\n",
        "2. **Entities are poorly defined** → Violates Rules 1 & 2  \n",
        "3. **Time-varying data isn't properly modeled** → Missing time-series tables\n",
        "\n",
        "**The test**: Can your normal data operations be expressed purely as INSERT and DELETE?\n",
        "- ✅ **Yes** → Schema is well-normalized and immutability-ready\n",
        "- ❌ **No** → Schema needs redesign\n",
        "\n",
        "**UPDATE exists** for the rare cases when data corruption or entry errors must be corrected surgically. It's a maintenance tool, not an operational tool.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Practical Example: Animal Research Lab\n",
        "\n",
        "Let's apply these principles to design a schema for tracking mice in a research lab.\n",
        "\n",
        "### ❌ Poor Design (Violates Normalization)\n",
        "\n",
        "```python\n",
        "@schema\n",
        "class Mouse(dj.Manual):\n",
        "    definition = \"\"\"\n",
        "    mouse_id : int\n",
        "    ---\n",
        "    date_of_birth : date          # ✓ Permanent property of mouse\n",
        "    sex : enum('M', 'F')          # ✓ Permanent property of mouse\n",
        "    cage_id : int                 # ✗ CHANGEABLE - violates Rule 3\n",
        "    current_weight : decimal(5,2) # ✗ CHANGEABLE - violates Rule 3\n",
        "    cage_location : varchar(50)   # ✗ Property of CAGE, not mouse - violates Rule 2\n",
        "    cage_capacity : int           # ✗ Property of CAGE, not mouse - violates Rule 2\n",
        "    \"\"\"\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ✅ Good Design (Properly Normalized)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/svg+xml": [
              "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"284pt\" height=\"114pt\" viewBox=\"0.00 0.00 283.50 114.00\">\n",
              "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 110)\">\n",
              "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-110 279.5,-110 279.5,4 -4,4\"/>\n",
              "<!-- Cage -->\n",
              "<g id=\"node1\" class=\"node\">\n",
              "<title>Cage</title>\n",
              "<g id=\"a_node1\"><a xlink:title=\"cage_id              &#13;------------------------------&#13;location             &#13;capacity             &#13;\">\n",
              "<polygon fill=\"#00ff00\" fill-opacity=\"0.188235\" stroke=\"#00ff00\" stroke-opacity=\"0.188235\" points=\"82,-106 35,-106 35,-71 82,-71 82,-106\"/>\n",
              "<text text-anchor=\"start\" x=\"43\" y=\"-86.4\" font-family=\"arial\" text-decoration=\"underline\" font-size=\"12.00\" fill=\"darkgreen\">Cage</text>\n",
              "</a>\n",
              "</g>\n",
              "</g>\n",
              "<!-- CageAssignment -->\n",
              "<g id=\"node2\" class=\"node\">\n",
              "<title>CageAssignment</title>\n",
              "<g id=\"a_node2\"><a xlink:title=\"→ Mouse&#13;assignment_date      &#13;------------------------------&#13;→ Cage&#13;\">\n",
              "<polygon fill=\"#00ff00\" fill-opacity=\"0.188235\" stroke=\"#00ff00\" stroke-opacity=\"0.188235\" points=\"117,-35 0,-35 0,0 117,0 117,-35\"/>\n",
              "<text text-anchor=\"start\" x=\"8\" y=\"-15.4\" font-family=\"arial\" text-decoration=\"underline\" font-size=\"12.00\" fill=\"darkgreen\">CageAssignment</text>\n",
              "</a>\n",
              "</g>\n",
              "</g>\n",
              "<!-- Cage&#45;&gt;CageAssignment -->\n",
              "<g id=\"edge1\" class=\"edge\">\n",
              "<title>Cage-&gt;CageAssignment</title>\n",
              "<path fill=\"none\" stroke=\"#000000\" stroke-width=\"0.75\" stroke-dasharray=\"5,2\" stroke-opacity=\"0.250980\" d=\"M58.5,-70.8C58.5,-59.95 58.5,-45.87 58.5,-35.05\"/>\n",
              "</g>\n",
              "<!-- Mouse -->\n",
              "<g id=\"node3\" class=\"node\">\n",
              "<title>Mouse</title>\n",
              "<g id=\"a_node3\"><a xlink:title=\"mouse_id             &#13;------------------------------&#13;date_of_birth        &#13;sex                  &#13;\">\n",
              "<polygon fill=\"#00ff00\" fill-opacity=\"0.188235\" stroke=\"#00ff00\" stroke-opacity=\"0.188235\" points=\"194.5,-106 138.5,-106 138.5,-71 194.5,-71 194.5,-106\"/>\n",
              "<text text-anchor=\"start\" x=\"146.5\" y=\"-86.4\" font-family=\"arial\" text-decoration=\"underline\" font-size=\"12.00\" fill=\"darkgreen\">Mouse</text>\n",
              "</a>\n",
              "</g>\n",
              "</g>\n",
              "<!-- Mouse&#45;&gt;CageAssignment -->\n",
              "<g id=\"edge2\" class=\"edge\">\n",
              "<title>Mouse-&gt;CageAssignment</title>\n",
              "<path fill=\"none\" stroke=\"#000000\" stroke-width=\"0.75\" stroke-opacity=\"0.250980\" d=\"M140.63,-70.97C123.66,-60.13 101.54,-46 84.53,-35.13\"/>\n",
              "</g>\n",
              "<!-- WeightMeasurement -->\n",
              "<g id=\"node4\" class=\"node\">\n",
              "<title>WeightMeasurement</title>\n",
              "<g id=\"a_node4\"><a xlink:title=\"→ Mouse&#13;measurement_date     &#13;------------------------------&#13;weight               &#13;\">\n",
              "<polygon fill=\"#00ff00\" fill-opacity=\"0.188235\" stroke=\"#00ff00\" stroke-opacity=\"0.188235\" points=\"275.5,-35 135.5,-35 135.5,0 275.5,0 275.5,-35\"/>\n",
              "<text text-anchor=\"start\" x=\"143.5\" y=\"-15.4\" font-family=\"arial\" text-decoration=\"underline\" font-size=\"12.00\" fill=\"darkgreen\">WeightMeasurement</text>\n",
              "</a>\n",
              "</g>\n",
              "</g>\n",
              "<!-- Mouse&#45;&gt;WeightMeasurement -->\n",
              "<g id=\"edge3\" class=\"edge\">\n",
              "<title>Mouse-&gt;WeightMeasurement</title>\n",
              "<path fill=\"none\" stroke=\"#000000\" stroke-width=\"0.75\" stroke-opacity=\"0.250980\" d=\"M175.94,-70.8C182.07,-59.95 190.03,-45.87 196.15,-35.05\"/>\n",
              "</g>\n",
              "</g>\n",
              "</svg>"
            ],
            "text/plain": [
              "<datajoint.diagram.Diagram at 0xffff5b9e0c30>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import datajoint as dj\n",
        "schema = dj.Schema('mouse_cage')\n",
        "\n",
        "# Entity 1: Mouse - contains ONLY permanent mouse properties\n",
        "@schema\n",
        "class Mouse(dj.Manual):\n",
        "    definition = \"\"\"\n",
        "    mouse_id : int\n",
        "    ---\n",
        "    date_of_birth : date          # ✓ Permanent property of mouse\n",
        "    sex : enum('M', 'F')          # ✓ Permanent property of mouse\n",
        "    \"\"\"\n",
        "\n",
        "# Entity 2: Cage - contains ONLY cage properties\n",
        "@schema\n",
        "class Cage(dj.Manual):\n",
        "    definition = \"\"\"\n",
        "    cage_id : int\n",
        "    ---\n",
        "    location : varchar(50)        # ✓ Property of cage\n",
        "    capacity : int                # ✓ Property of cage\n",
        "    \"\"\"\n",
        "\n",
        "# Entity 3: CageAssignment - represents the relationship (changeable over time)\n",
        "@schema\n",
        "class CageAssignment(dj.Manual):\n",
        "    definition = \"\"\"\n",
        "    -> Mouse\n",
        "    assignment_date : date        # Part of primary key - tracks assignment history\n",
        "    ---\n",
        "    -> Cage\n",
        "    \"\"\"\n",
        "\n",
        "# Entity 4: WeightMeasurement - time-series of measurements\n",
        "@schema\n",
        "class WeightMeasurement(dj.Manual):\n",
        "    definition = \"\"\"\n",
        "    -> Mouse\n",
        "    measurement_date : date        # Part of primary key - tracks measurement history\n",
        "    ---\n",
        "    weight : decimal(5,2)         # ✓ Weight at this specific date\n",
        "    \"\"\"\n",
        "\n",
        "dj.Diagram(schema)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Why this is better:**\n",
        "\n",
        "1. **✅ Rule 1 (One entity per table)**: Four distinct entity types, each in its own table\n",
        "2. **✅ Rule 2 (Attributes describe only that entity)**: Mouse table has only mouse properties; Cage table has only cage properties\n",
        "3. **✅ Rule 3 (Separate changeable attributes)**: Cage assignments and weights are in separate tables\n",
        "4. **No updates needed**: Moving a mouse means DELETE old assignment + INSERT new assignment\n",
        "5. **No redundancy**: Cage properties stored once, referenced by assignments\n",
        "6. **History preserved**: Can track all past cage assignments and weight measurements\n",
        "7. **Immutable entities**: Mouse and Cage entities never change once created\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## The Workflow Immutability Principle\n",
        "\n",
        "A key insight in DataJoint's Entity-Workflow Model: **workflow artifacts are immutable once created**.\n",
        "\n",
        "### Workflow Entities as Immutable Artifacts\n",
        "\n",
        "**Concept**: Each row (tuple) represents an immutable workflow artifact created at a specific workflow step. Once created, these artifacts are not modified—only created or destroyed.\n",
        "\n",
        "**Operations:**\n",
        "- ✅ **INSERT**: Create new workflow entities\n",
        "- ✅ **DELETE**: Remove workflow entities and their downstream artifacts\n",
        "- ❌ **UPDATE**: Avoided by design\n",
        "\n",
        "### Why Workflow Immutability Matters\n",
        "\n",
        "1. **Foreign keys reference complete workflow artifacts**: When a table references another via foreign key, it references the entire workflow entity created at a specific step. Updates can break these workflow relationships in subtle ways.\n",
        "\n",
        "2. **Workflow execution dependencies**: In computational workflows, downstream entities are created from upstream entities. Updating upstream entities invalidates downstream workflow artifacts, but foreign key constraints won't detect this. Deletion forces you to explicitly address workflow dependencies.\n",
        "\n",
        "3. **Workflow provenance and audit trails**: Immutable workflow artifacts naturally preserve the history of workflow execution. Changes are represented as new workflow artifacts, not modifications to existing ones.\n",
        "\n",
        "4. **Parallel workflow execution**: Immutable workflow artifacts can be safely read by multiple processes without locks, enabling parallel workflow execution.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example: Data Pipeline and Immutability\n",
        "\n",
        "Consider an image processing pipeline:\n",
        "\n",
        "```\n",
        "RawImage → PreprocessedImage → SegmentedCells → CellActivity\n",
        "```\n",
        "\n",
        "**If you UPDATE `RawImage` parameters:**\n",
        "- ✗ All downstream data (`PreprocessedImage`, `SegmentedCells`, `CellActivity`) becomes invalid\n",
        "- ✗ No error is raised—the inconsistency is silent\n",
        "- ✗ Results are now based on mismatched inputs\n",
        "\n",
        "**If you DELETE and re-INSERT `RawImage`:**\n",
        "- ✓ Foreign key constraint prevents deletion while downstream data exists\n",
        "- ✓ Forces you to delete the entire downstream pipeline first\n",
        "- ✓ Then recompute everything with correct parameters\n",
        "- ✓ Data dependencies are explicit and enforced\n",
        "\n",
        "This is why normalization naturally leads to immutability: properly normalized schemas make data dependencies explicit through foreign keys, and immutability ensures those dependencies remain valid.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Additional Example: E-commerce System\n",
        "\n",
        "Another domain to illustrate the principles:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/svg+xml": [
              "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"168pt\" height=\"185pt\" viewBox=\"0.00 0.00 168.00 185.00\">\n",
              "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 181)\">\n",
              "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-181 164,-181 164,4 -4,4\"/>\n",
              "<!-- Order -->\n",
              "<g id=\"node1\" class=\"node\">\n",
              "<title>Order</title>\n",
              "<g id=\"a_node1\"><a xlink:title=\"order_id             &#13;\">\n",
              "<polygon fill=\"#00ff00\" fill-opacity=\"0.188235\" stroke=\"#00ff00\" stroke-opacity=\"0.188235\" points=\"51,-106 0,-106 0,-71 51,-71 51,-106\"/>\n",
              "<text text-anchor=\"start\" x=\"8\" y=\"-86.4\" font-family=\"arial\" text-decoration=\"underline\" font-size=\"12.00\" fill=\"darkgreen\">Order</text>\n",
              "</a>\n",
              "</g>\n",
              "</g>\n",
              "<!-- OrderItem -->\n",
              "<g id=\"node2\" class=\"node\">\n",
              "<title>OrderItem</title>\n",
              "<g id=\"a_node2\"><a xlink:title=\"→ Order&#13;→ ProductPrice&#13;------------------------------&#13;quantity             &#13;\">\n",
              "<polygon fill=\"#00ff00\" fill-opacity=\"0.188235\" stroke=\"#00ff00\" stroke-opacity=\"0.188235\" points=\"109,-35 30,-35 30,0 109,0 109,-35\"/>\n",
              "<text text-anchor=\"middle\" x=\"69.5\" y=\"-14.4\" font-family=\"arial\" font-size=\"12.00\" fill=\"darkgreen\">OrderItem</text>\n",
              "</a>\n",
              "</g>\n",
              "</g>\n",
              "<!-- Order&#45;&gt;OrderItem -->\n",
              "<g id=\"edge1\" class=\"edge\">\n",
              "<title>Order-&gt;OrderItem</title>\n",
              "<path fill=\"none\" stroke=\"#000000\" stroke-width=\"0.75\" stroke-opacity=\"0.250980\" d=\"M36.15,-70.8C43.07,-59.95 52.05,-45.87 58.95,-35.05\"/>\n",
              "</g>\n",
              "<!-- Product -->\n",
              "<g id=\"node3\" class=\"node\">\n",
              "<title>Product</title>\n",
              "<g id=\"a_node3\"><a xlink:title=\"product_id           &#13;------------------------------&#13;name                 &#13;description          &#13;manufacturer         &#13;\">\n",
              "<polygon fill=\"#00ff00\" fill-opacity=\"0.188235\" stroke=\"#00ff00\" stroke-opacity=\"0.188235\" points=\"145.5,-177 83.5,-177 83.5,-142 145.5,-142 145.5,-177\"/>\n",
              "<text text-anchor=\"start\" x=\"91.5\" y=\"-157.4\" font-family=\"arial\" text-decoration=\"underline\" font-size=\"12.00\" fill=\"darkgreen\">Product</text>\n",
              "</a>\n",
              "</g>\n",
              "</g>\n",
              "<!-- ProductPrice -->\n",
              "<g id=\"node4\" class=\"node\">\n",
              "<title>ProductPrice</title>\n",
              "<g id=\"a_node4\"><a xlink:title=\"→ Product&#13;effective_date       &#13;------------------------------&#13;price                &#13;\">\n",
              "<polygon fill=\"#00ff00\" fill-opacity=\"0.188235\" stroke=\"#00ff00\" stroke-opacity=\"0.188235\" points=\"160,-106 69,-106 69,-71 160,-71 160,-106\"/>\n",
              "<text text-anchor=\"start\" x=\"77\" y=\"-86.4\" font-family=\"arial\" text-decoration=\"underline\" font-size=\"12.00\" fill=\"darkgreen\">ProductPrice</text>\n",
              "</a>\n",
              "</g>\n",
              "</g>\n",
              "<!-- Product&#45;&gt;ProductPrice -->\n",
              "<g id=\"edge2\" class=\"edge\">\n",
              "<title>Product-&gt;ProductPrice</title>\n",
              "<path fill=\"none\" stroke=\"#000000\" stroke-width=\"0.75\" stroke-opacity=\"0.250980\" d=\"M114.5,-141.8C114.5,-130.95 114.5,-116.87 114.5,-106.05\"/>\n",
              "</g>\n",
              "<!-- ProductPrice&#45;&gt;OrderItem -->\n",
              "<g id=\"edge3\" class=\"edge\">\n",
              "<title>ProductPrice-&gt;OrderItem</title>\n",
              "<path fill=\"none\" stroke=\"#000000\" stroke-width=\"0.75\" stroke-opacity=\"0.250980\" d=\"M103.61,-70.8C96.53,-59.95 87.35,-45.87 80.29,-35.05\"/>\n",
              "</g>\n",
              "</g>\n",
              "</svg>"
            ],
            "text/plain": [
              "<datajoint.diagram.Diagram at 0xffff5b9e02b0>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "schema = dj.Schema('ecommerce')\n",
        "\n",
        "# Permanent product properties\n",
        "@schema\n",
        "class Product(dj.Manual):\n",
        "    definition = \"\"\"\n",
        "    product_id : int\n",
        "    ---\n",
        "    name : varchar(100)           # ✓ Permanent\n",
        "    description : varchar(500)    # ✓ Permanent\n",
        "    manufacturer : varchar(100)   # ✓ Permanent\n",
        "    # NOT current_price - prices change!\n",
        "    \"\"\"\n",
        "\n",
        "# Changeable pricing - separate entity\n",
        "@schema\n",
        "class ProductPrice(dj.Manual):\n",
        "    definition = \"\"\"\n",
        "    -> Product\n",
        "    effective_date : date         # When this price became effective\n",
        "    ---\n",
        "    price : decimal(10,2)\n",
        "    \"\"\"\n",
        "\n",
        "@schema\n",
        "class Order(dj.Manual):\n",
        "    definition = \"\"\"\n",
        "    order_id : int\n",
        "    \"\"\"\n",
        "\n",
        "# Customer orders reference the product, not a specific price\n",
        "@schema\n",
        "class OrderItem(dj.Manual):\n",
        "    definition = \"\"\"\n",
        "    -> Order\n",
        "    -> ProductPrice               # Which price was in effect for each product\n",
        "    ---\n",
        "    quantity : int\n",
        "    \"\"\"\n",
        "\n",
        "dj.Diagram(schema)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tidy Data: Normalization Rediscovered\n",
        "\n",
        "The principles of normalization have been independently rediscovered and reinterpreted beyond relational database design. For example the R programming language community defined **\"tidy data\"** [@doi.org/10.18637/jss.v059.i10] principles to structure data uniformly for consistent manipulation and visualization, converting \"messy data\" into \"tidy data.\"\n",
        "\n",
        "**Tidy data principles:**\n",
        "1. Each variable forms a column\n",
        "2. Each observation forms a row\n",
        "3. Each type of observational unit forms a separate table\n",
        "\n",
        "**Mapping to normalization:**\n",
        "- Principle 1 & 2 → **1NF** (atomic values, no repeating groups)\n",
        "- Principle 3 → **Entity normalization** (one entity type per table)\n",
        "\n",
        "This demonstrates that normalization principles are fundamental to data organization, emerging naturally even when approached from different perspectives (database theory vs. data analysis practice). The same insights appear whether you start from predicate calculus, entity modeling, workflow execution, or data manipulation needs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key insight**: Price is a time-varying property, so it becomes its own entity rather than an attribute of Product. Order items reference both the specific product price and, transitively, the product itself, preserving historical accuracy.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example: Three Perspectives on the Same Problem\n",
        "\n",
        "Let's see how each approach would analyze a problematic table design:\n",
        "\n",
        "**Problematic design:**\n",
        "```\n",
        "ExperimentData table\n",
        "┌─────────┬──────────┬──────┬─────────┬────────────┬────────────┬───────────┐\n",
        "│ exp_id* │ mouse_id │ sex  │ genotype│ session_id │ record_date│ spike_rate│\n",
        "├─────────┼──────────┼──────┼─────────┼────────────┼────────────┼───────────┤\n",
        "│ 1       │ M001     │ M    │ WT      │ S1         │ 2024-01-15 │ 45.3      │\n",
        "│ 2       │ M001     │ M    │ WT      │ S2         │ 2024-01-22 │ 52.1      │\n",
        "│ 3       │ M002     │ F    │ KO      │ S3         │ 2024-01-16 │ 38.7      │\n",
        "└─────────┴──────────┴──────┴─────────┴────────────┴────────────┴───────────┘\n",
        "```\n",
        "\n",
        "### Mathematical Normalization Analysis\n",
        "\n",
        "**Identify functional dependencies:**\n",
        "- `exp_id → mouse_id, session_id, record_date, spike_rate`\n",
        "- `mouse_id → sex, genotype` (transitive dependency!)\n",
        "- `session_id → mouse_id, record_date` (could be a partial dependency issue)\n",
        "\n",
        "**Problems identified:**\n",
        "- **Violates 3NF**: `sex` and `genotype` transitively depend on `exp_id` through `mouse_id`\n",
        "  - `exp_id → mouse_id → sex`\n",
        "  - `exp_id → mouse_id → genotype`\n",
        "\n",
        "**Solution**: Decompose to eliminate transitive dependencies\n",
        "```\n",
        "Mouse(mouse_id*, sex, genotype)\n",
        "ExperimentData(exp_id*, mouse_id, session_id, record_date, spike_rate)\n",
        "```\n",
        "\n",
        "### Entity Normalization Analysis\n",
        "\n",
        "**Identify entity types:**\n",
        "- **Mouse**: A research subject with biological properties\n",
        "- **Session**: An experimental session\n",
        "- **Recording**: Data collected during a session\n",
        "\n",
        "**Problems identified:**\n",
        "- Table mixes attributes from **multiple entity types**:\n",
        "  - `sex`, `genotype` describe **Mouse** entity\n",
        "  - `session_id`, `record_date` describe **Session** entity\n",
        "  - `spike_rate` describes **Recording** entity (the actual measurement)\n",
        "- **Question**: \"Is `sex` a property of an experiment?\" No, it's a property of the mouse\n",
        "\n",
        "**Solution**: Separate entity types into their own tables\n",
        "```\n",
        "Mouse(mouse_id*, sex, genotype)\n",
        "Session(session_id*, mouse_id, record_date)\n",
        "Recording(exp_id*, session_id, spike_rate)\n",
        "```\n",
        "\n",
        "### Workflow Normalization Analysis\n",
        "\n",
        "**Identify workflow steps:**\n",
        "1. **Mouse registration**: Enter mouse into colony (creates Mouse entities)\n",
        "2. **Session creation**: Experimenter plans/conducts session (creates Session entities)\n",
        "3. **Data recording**: Acquisition system records data (creates Recording entities)\n",
        "\n",
        "**Problems identified:**\n",
        "- Table mixes entities created at **different workflow steps**:\n",
        "  - `sex`, `genotype` created at **mouse registration** (step 1)\n",
        "  - `session_id`, `record_date` created at **session creation** (step 2)\n",
        "  - `spike_rate` created during **data acquisition** (step 3)\n",
        "- **Questions**: \n",
        "  - \"When is each attribute created?\"\n",
        "  - \"Can we record spike_rate before creating the session?\" No—violates workflow order\n",
        "\n",
        "**Solution**: Separate workflow steps, establish dependencies\n",
        "```\n",
        "Mouse(mouse_id*, sex, genotype)                    ← Step 1: Register mouse\n",
        "    ↓ (must exist before session)\n",
        "Session(session_id*, mouse_id, record_date)       ← Step 2: Create session\n",
        "    ↓ (must exist before recording)\n",
        "Recording(exp_id*, session_id, spike_rate)        ← Step 3: Record data\n",
        "```\n",
        "\n",
        "### Convergence\n",
        "\n",
        "**All three approaches identify the same problems and lead to the same solution:**\n",
        "- Separate Mouse, Session, and Recording into distinct tables\n",
        "- Use foreign keys to establish relationships/dependencies\n",
        "- Eliminate redundancy of mouse attributes\n",
        "\n",
        "**But they use different reasoning:**\n",
        "- **Mathematical**: Abstract functional dependencies\n",
        "- **Entity**: Concrete entity types and their properties\n",
        "- **Workflow**: Temporal sequence of operations\n",
        "\n",
        "**Choose the perspective that makes most sense for your context.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Comparing the Three Approaches\n",
        "\n",
        "All three approaches to normalization lead to well-structured, anomaly-free databases, but they differ in their conceptual foundations and how they guide the design process:\n",
        "\n",
        "| Aspect | Mathematical (Codd) | Entity (Chen) | Workflow (DataJoint) |\n",
        "|--------|-------------------|---------------|---------------------|\n",
        "| **Foundation** | Predicate calculus, functional dependencies | Entity types and their properties | Workflow steps creating entities |\n",
        "| **Conceptual Model** | Relations as predicates | Entities and relationships | Workflow execution graph (DAG) |\n",
        "| **Core Question** | \"What functional dependencies exist?\" | \"What entity types exist?\" | \"When/how are entities created?\" |\n",
        "| **Design Method** | Identify dependencies, decompose | Identify entities, separate entity types | Identify workflow steps, separate by workflow steps |\n",
        "| **Reasoning Style** | Abstract, mathematical | Concrete, intuitive | Temporal, operational |\n",
        "| **Primary Focus** | Attribute-level dependencies | Entity-level coherence | Workflow-level dependencies |\n",
        "| **Foreign Keys** | Referential integrity | Entity relationships | Workflow dependencies + referential integrity |\n",
        "| **Time Dimension** | Not addressed | Not central | Fundamental |\n",
        "| **Cyclic Dependencies** | Not prohibited | Not addressed | Explicitly prohibited (DAG) |\n",
        "| **Complexity** | Requires formal analysis | Natural domain mapping | Requires workflow understanding |\n",
        "| **Accessibility** | Less accessible | More accessible | Most accessible for computational workflows |\n",
        "| **Result** | Normalized schema | Normalized schema | Normalized schema + workflow structure |\n",
        "\n",
        "### The Progression of Ideas\n",
        "\n",
        "These three approaches represent an **evolution in thinking** about database normalization:\n",
        "\n",
        "1. **Mathematical normalization (1970s)**: Provides mathematical rigor but requires abstract reasoning about functional dependencies\n",
        "2. **Entity normalization (1976)**: Makes normalization more intuitive by grounding it in entity types, which map naturally to domain understanding\n",
        "3. **Workflow normalization (2000s)**: Extends entity normalization with temporal/operational dimensions, making it ideal for computational and scientific workflows\n",
        "\n",
        "**Key insight**: Each approach builds on the previous, making normalization progressively more accessible while maintaining the same rigorous results. Mathematical normalization provides the theory, entity normalization makes it practical, and workflow normalization makes it operational.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### How the Approaches Correspond\n",
        "\n",
        "While using different reasoning, all three approaches identify the same normalization problems:\n",
        "\n",
        "**Problem: Repeating groups (e.g., courses as comma-separated list)**\n",
        "- **Mathematical**: Violates 1NF (non-atomic values)\n",
        "- **Entity**: Multiple entity instances stored in single attribute\n",
        "- **Workflow**: Multiple workflow artifacts conflated into one\n",
        "\n",
        "**Problem: Student name duplicated in enrollment table**\n",
        "- **Mathematical**: Violates 2NF (partial dependency: student_name depends only on student_id, not full key)\n",
        "- **Entity**: Attribute describes different entity type (Student, not Enrollment)\n",
        "- **Workflow**: Attribute from different workflow step (student registration, not enrollment)\n",
        "\n",
        "**Problem: Department info in student table**\n",
        "- **Mathematical**: Violates 3NF (transitive dependency: student_id → dept_code → dept_building)\n",
        "- **Entity**: Attribute describes different entity type (Department, not Student)\n",
        "- **Workflow**: Attribute from different workflow step (department creation, not student registration)\n",
        "\n",
        "**Problem: Mouse properties and genotype in same table**\n",
        "- **Mathematical**: Might satisfy 3NF (depends on interpretation)\n",
        "- **Entity**: Might be acceptable (all describe Mouse entity)\n",
        "- **Workflow**: Violates workflow normalization (created at different workflow steps)\n",
        "\n",
        "**Problem: Order with payment, shipment, and delivery dates**\n",
        "- **Mathematical**: ✅ Satisfies 3NF (all attributes depend directly on order_id)\n",
        "- **Entity**: ✅ Acceptable (all describe properties of the Order entity)\n",
        "- **Workflow**: ❌ Violates workflow normalization (each date created at different workflow step)\n",
        "\n",
        "**This shows:** Workflow normalization is the **strictest** form, requiring temporal separation that the other approaches don't mandate. Tables can be perfectly normalized under mathematical and entity approaches yet still require further decomposition under workflow normalization to enforce temporal sequences and workflow dependencies.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary: Three Perspectives on Normalization\n",
        "\n",
        "### Unified Goal, Different Perspectives\n",
        "\n",
        "All three normalization approaches aim to eliminate anomalies and create well-structured schemas. They converge on the same design principles but approach them from different conceptual foundations:\n",
        "\n",
        "**1. Mathematical Normalization (Codd)**\n",
        "- **Core principle**: \"Every non-key attribute must depend on the key, the whole key, and nothing but the key\"\n",
        "- **Approach**: Analyze functional dependencies, eliminate violations of normal forms\n",
        "- **Strength**: Mathematical rigor and formal provability\n",
        "- **Best for**: Theoretical foundations, automated schema verification\n",
        "\n",
        "**2. Entity Normalization (Chen)**\n",
        "- **Core principle**: \"Each table represents exactly one entity type; all attributes describe that entity directly\"\n",
        "- **Approach**: Identify entity types in domain, create one table per entity type\n",
        "- **Strength**: Intuitive mapping to domain understanding\n",
        "- **Best for**: Initial schema design, domain modeling\n",
        "\n",
        "**3. Workflow Normalization (DataJoint)**\n",
        "- **Core principle**: \"Each table represents entities created at one workflow step; attributes describe entities at that step\"\n",
        "- **Approach**: Map workflow steps to tables, ensure temporal coherence\n",
        "- **Strength**: Explicit workflow dependencies, temporal integrity\n",
        "- **Best for**: Computational workflows, scientific data pipelines\n",
        "\n",
        "### Choosing Your Perspective\n",
        "\n",
        "**When designing a new schema:**\n",
        "1. Start with **entity normalization**: \"What entity types exist in my domain?\"\n",
        "2. Apply **workflow normalization** if applicable: \"When/how is each entity created?\"\n",
        "3. Verify with **mathematical normalization**: \"Are there any hidden functional dependencies?\"\n",
        "\n",
        "**When reviewing an existing schema:**\n",
        "1. Check **mathematical normalization**: \"Does it satisfy 1NF, 2NF, 3NF?\"\n",
        "2. Check **entity normalization**: \"Does each table represent one coherent entity type?\"\n",
        "3. Check **workflow normalization** (if applicable): \"Are workflow dependencies explicit and enforced?\"\n",
        "\n",
        "### The Evolution of Normalization\n",
        "\n",
        "These approaches represent an evolution in our understanding of database design:\n",
        "\n",
        "- **1970s**: Codd provides mathematical foundations based on functional dependencies\n",
        "- **1976**: Chen makes normalization accessible by grounding it in entity types\n",
        "- **2000s**: DataJoint extends normalization to explicitly model temporal/workflow aspects\n",
        "\n",
        "**Key insight**: Each approach builds on its predecessors, making normalization progressively more practical while maintaining theoretical rigor. Choose the perspective that best matches your domain and needs.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Benefits of Well-Normalized Schemas\n",
        "\n",
        "When normalization principles are properly applied (regardless of which approach you use):\n",
        "\n",
        "**Universal benefits:**\n",
        "- ✅ **No Anomalies**: Update, insertion, and deletion anomalies eliminated\n",
        "- ✅ **Data Integrity**: Constraints ensure consistency\n",
        "- ✅ **Maintainability**: Changes are localized to specific tables\n",
        "- ✅ **Clear Structure**: Schema reflects domain organization\n",
        "- ✅ **Reduced Redundancy**: Each fact stored once\n",
        "\n",
        "**Additional benefits from workflow normalization:**\n",
        "- ✅ **Workflow Integrity**: Each workflow artifact created in exactly one place\n",
        "- ✅ **Workflow Consistency**: Changes propagate correctly through workflow dependencies\n",
        "- ✅ **Workflow Immutability**: Workflow artifacts remain stable; changes tracked explicitly\n",
        "- ✅ **Workflow Provenance**: Workflow execution history naturally preserved\n",
        "- ✅ **Explicit Dependencies**: DAG structure ensures valid operation sequences\n",
        "\n",
        "### Practical Application\n",
        "\n",
        "**For entity-based design:**\n",
        "1. Identify entity types in your domain\n",
        "2. Create one table per entity type\n",
        "3. Ensure attributes describe only that entity type\n",
        "4. Use foreign keys for relationships between entities\n",
        "5. Verify no partial or transitive dependencies\n",
        "\n",
        "**For workflow-based design:**\n",
        "1. Identify workflow steps in your domain\n",
        "2. For each workflow step, determine what entities are created\n",
        "3. Separate workflow steps into distinct tables\n",
        "4. Model workflow dependencies with foreign keys\n",
        "5. Verify schema forms a DAG (no cycles)\n",
        "6. Ensure entities created at different times are in separate tables\n",
        "\n",
        "**For verification using mathematical normalization:**\n",
        "1. Check 1NF: All attributes atomic\n",
        "2. Check 2NF: No partial dependencies on composite keys\n",
        "3. Check 3NF: No transitive dependencies through non-key attributes\n",
        "4. Document all functional dependencies\n",
        "\n",
        "All three approaches lead to robust, maintainable schemas that accurately represent your domain.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
